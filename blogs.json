[
    {
        "id": "kape",
        "title": "TryHackMe | KAPE",
        "content": "<p><strong>After completing Redline, I moved on to KAPE and quickly realised how powerful it is for automating the DFIR workflow we practised in Windows Forensics 1 and 2. It also helped me understand how individual forensic utilities can be chained together for faster, consistent triage and analysis (e.g. EZViewer).</strong></p><h3>Learning KAPE's Structure</h3><p>I discovered that KAPE's targets and modules work together, with .tkape files defining what to collect and .mkape files determining how to process that data. Understanding the use of variables like %d for timestamps and %m for machine names gave me insight into how KAPE organises forensic data efficiently.</p><h3>Hands-On Experience</h3><p>Using both the GUI (gkape.exe) and CLI (kape.exe) deepened my appreciation for automation in forensics. The ability to gather key Windows artefacts, registry hives, and logs with KapeTriage and then process them using the EZParser module streamlined tasks that would otherwise require multiple manual tools. Although the processing time was long, the workflow was intuitive once I understood the logic behind targets and modules.</p><h3>Challenges and Insights</h3><p>Some hands-on tasks were tricky, especially identifying software installations from network drives, but they forced me to think critically about artefact locations and data correlation. I learned how to use EZViewer effectively for exploring CSV outputs and realised how KAPE works perfectly with Zimmerman's ecosystem for a complete forensic workflow.</p><h3>Reflection</h3><p>This lab reinforced the importance of automation in DFIR and gave me practical exposure to modular forensic collection. While some steps were frustrating, especially without hints, the process taught me how to think like a forensic investigator, methodically, patiently, and with a focus on evidence correlation. I now feel more confident using KAPE to automate and speed up forensic analysis in real investigations.</p>",
        "author": "Tom Page",
        "date_published": "17/10/2025",
        "read_time": "2 min read",
        "featured_image": "/static/images/kape.png",
        "tags": ["TryHackMe", "KAPE", "Windows", "Forensics"],
        "seo_title": "TryHackMe - KAPE",
        "seo_description": "Exploring the fundamentals of KAPE with TryHackMe. Learning key concepts, tools, and processes to investigate security incidents effectively."
    },
    {
        "id": "redline",
        "title": "TryHackMe | Redline",
        "content": "<p><strong>After wrapping up the Autopsy room, I moved on to learning about Redline, a tool I'd never heard of before. This is one of the things I'm loving about this course: going head first into something completely new and making sense of it on the go.</strong></p> <h3>First Impressions of Redline</h3> <p>Redline is built by FireEye and focuses on endpoint analysis by collecting and investigating artefacts from compromised systems. Compared to Autopsy, it feels more investigative than exploratory. Instead of sifting through a full disk image, you work with targeted data collections that can be tuned for specific purposes, like searching for indicators of compromise (IOCs). I quickly learnt how powerful it can be when you want to focus on a particular threat.</p> <h3>Getting the Data</h3> <p>The first challenge came during data collection. Redline needs an empty directory to store its output, and the default folder already had files in it. It just goes to show that forensics often isn't always a complex technical puzzle, but about noticing the small details that can stop your workflow cold. Once I fixed it and ran my collection, I saw how Redline builds structured snapshots of a system, including memory, processes, network connections, event logs, and more. It's like taking a digital X-ray of the host at a given point in time.</p> <h3>Diving into the Interface</h3> <p>When I first opened the analysis in Redline, the many tabs, filters, and categories felt overwhelming. Eventually, though, I started to get the hang of it. System Information gave me the user and OS context, while Event Logs, Scheduled Tasks, and File Download History revealed behavioural traces. What stood out most was how Redline connects system events in a way that highlights persistence, suspicious downloads, and even custom event IDs left behind by an intruder.</p> <h3>Spotting Suspicious Activity</h3> <p>This room required both technical skill and investigative thinking. I saw examples of fake scheduled tasks, unusual event logs, and even a playful message left behind by an attacker. I was fascinated by seeing how each artefact told a small part of the story, scheduled persistence, file downloads, password changes, and even hidden messages buried inside tasks or logs.</p> <h3>Working with IOCs</h3> <p>Redline's IOC Search Collector introduced me to scanning a system based on specific indicators such as domains, hashes, filenames, etc. This means that instead of searching for everything, you can target what's relevant. This was also my first time working with .ioc files, and it gave me a better understanding of how analysts automate threat detection. I was able to trace a keylogger masquerading as another executable, identify its owner, and see how Redline ties it all together in a reportable view.</p> <h3>Patience in Forensics</h3> <p>If Autopsy taught me to interpret large volumes of data, Redline taught me patience. Waiting for analysis files to load (at one point up to 20 minutes!) was easily the most frustrating part of this room. However, this wait just shows that investigations take time, and patience often separates a rushed guess from a confident conclusion.</p> <h3>Connecting the Dots</h3> <p>Once everything was loaded, that's when the fun started. From discovering a fake update task to tracing a malicious download that led to a Cerber ransomware infection, each clue built on the previous one. The process showed how an attacker entered, persisted, downloaded payloads, and left. Seeing how all those artefacts related made the time investment worth it.</p> <h3>What I Learned</h3> <ul> <li><strong>Structured Analysis: </strong>Redline reinforces structured analysis through collecting, correlating, and confirming evidence step by step.</li> <li><strong>IOC Searches: </strong>IOC-based searching is powerful when you already have known indicators from threat intelligence or malware reports.</li> <li><strong>Be Patient: </strong>Patience is part of digital forensics. The best findings come from waiting, rechecking, and cross-referencing.</li> <li><strong>Tool Adaptation: </strong>Not all challenges are technical; sometimes you need to adapt your workflow to work with the tool.</li> <li><strong>Build the Story: </strong>Every artefact contributes to a bigger narrative, especially when viewed together through event logs, tasks, and file history.</li> </ul> <h3>Final Thoughts</h3> <p>This room was both frustrating and fascinating. The waiting times dragged, but the analysis process reminded me why I enjoy this field; every clue connects to another, and every investigation is a puzzle waiting to be solved. During this process, I have been learning how to think like an analyst, not just how to follow steps but question, verify, and dig deeper. Redline might have been slow to load, but it demonstrated how methodical endpoint investigations can be.</p>",
        "author": "Tom Page",
        "date_published": "10/10/2025",
        "read_time": "6 min read",
        "featured_image": "/static/images/redline.png",
        "tags": ["TryHackMe", "Redline", "Windows", "Forensics"],
        "seo_title": "TryHackMe - Redline",
        "seo_description": "Exploring the fundamentals of Redline with TryHackMe. Learning key concepts, tools, and processes to investigate security incidents effectively."
    },
    {
        "id": "autopsy",
        "title": "TryHackMe | Autopsy",
        "content": "<p><strong>After digging into Windows and Linux forensics, this room shifted gears and introduced me to Autopsy, a tool I'd heard of but never properly used. Unlike the command-line heavy Linux room, this one was all about working with a GUI, and I quickly learned that mastering the interface is just as much a skill as knowing which artefact to investigate.</strong></p> <h3>Why Autopsy Matters</h3> <p>What struck me right away is that Autopsy doesn't just present raw data, it organises it. In Windows Forensics, for example, I had to manually hunt through registry hives. Autopsy, on the other hand, puts everything in one place with categories like “Deleted Files,” “Installed Programs,” and “Interesting Items.” This taught me that a big part of forensic work isn't only finding data, it's managing and interpreting it efficiently.</p> <h3>The Learning Curve of a GUI</h3> <p>My initial challenge wasn't with the forensics but the tool instead. Just like with Registry Explorer earlier, I spent a surprising amount of time figuring out where things were. Once I realised that Autopsy uses a case-based workflow (with its own file extension, <code>.aut</code>), it started to make sense. I now see why organisations lean on tools like this. When working with large disk images, having everything indexed and searchable is invaluable.</p> <h3>Artefacts Look Different, Lessons Stay the Same</h3> <p>Autopsy exposed me to a wide variety of artefacts, from deleted files to sticky notes to web search history. Although these look different from Windows registry keys or Linux logs, they still build upon the same skill, piecing together the fragments into a story. For example, seeing installed software, network shares, and search queries side by side gave me a better sense of how all these traces interact to describe user behaviour.</p> <h3>Timelines Tell Stories</h3> <p>The timeline feature was extremely useful. Instead of looking at artefacts in isolation, I could zoom in on a single day and see everything that happened: files opened, programs run, and searches performed. It is a tool to help visualise a complete timeline of when events happened and how they link together. It provided that in a tangible way that raw logs or registry values don't.</p> <h3>Challenges and Surprises</h3> <p>Not everything was smooth sailing. I struggled to locate specific files (Sticky Notes, in particular, gave me a hard time), and at times, I had to look for external guidance. But I see that as part of the process. What I realised is that even when tools are powerful, they won't always give you the answer, you still need persistence, focus, and sometimes a bit of creative searching.</p> <h3>What I Took Away</h3> <ul> <li><strong>Learn the Workflow: </strong>Autopsy streamlines the analysis process, but it requires learning its workflow and structure first.</li> <li><strong>GUI Navigation: </strong>GUI-based tools don't remove complexity; they shift it from command syntax to navigation and interpretation.</li> <li><strong>Cross-Platform Skills: </strong>Artefacts may look different across Windows, Linux, and Autopsy cases, but the skill of building a timeline and narrative is constant.</li> <li><strong>Use Timelines: </strong>Timelines are one of the most powerful ways to transform isolated artefacts into a bigger picture of system behaviour.</li> <li><strong>Keep Trying: </strong>Struggling with searches reminded me that forensic work isn't about perfection; it's about persistence and learning from mistakes.</li> </ul> <h3>Final Thoughts</h3> <p>This room felt like my first real taste of professional forensic tooling. Where the earlier rooms taught me to dig into individual artefacts, Autopsy showed me how those pieces come together in a case-driven workflow. My biggest lesson here is that if in doubt, be methodical, stay curious, and that every trace contributes to the story a system is trying to tell.</p>",
        "author": "Tom Page",
        "date_published": "03/10/2025",
        "read_time": "5 min read",
        "featured_image": "/static/images/autopsy.png",
        "tags": ["TryHackMe", "Autopsy", "Windows", "Forensics"],
        "seo_title": "TryHackMe - Autopsy",
        "seo_description": "Exploring the fundamentals of Autopsy with TryHackMe. Learning key concepts, tools, and processes to investigate security incidents effectively."
    },
    {
        "id": "linux-forensics",
        "title": "TryHackMe | Linux Forensics",
        "content": "<p><strong>After completing both Windows Forensics rooms, I've taken my first steps into Linux Forensics. I was inexperienced with Linux going into this, so I expected a bit of struggle, but what surprised me was how much of what I'd already learned in Windows applied here, too, showing every action leaves a trace, you just need to know where to look.</strong></p> <h3>Linux Forensics vs Windows Forensics</h3> <p>Coming from Windows, the most significant difference I noticed was how open Linux is. In Windows, forensic data often hides deep inside the registry or specialised system files. In Linux, so much of it is exposed in simple text files. At first, this made things feel almost easy, but as I spent more time in this module, I found the real challenge is knowing what matters in that sea of information.</p> <h3>Accounts and Identity</h3> <p>One of my first lessons was just how much you can learn about user accounts from files like <code>/etc/passwd</code> and <code>/etc/group</code>. It reminded me of the SAM hive in Windows: different structure, same purpose. Seeing how UIDs and groups tie activity back to specific users made me realise that identity is a universal starting point in forensics, no matter the operating system.</p> <h3>System Configuration as Evidence</h3> <p>Looking at hostnames, timezones, and active processes showed me that configuration details aren't just background, they can be key forensic context. For example, discovering a service listening on <code>127.0.0.1:5901</code> wasn't just a technical answer, it was a clue about how the system was being accessed. Just like registry keys in Windows, these details help explain the bigger picture of system behaviour.</p> <h3>Persistence and Execution</h3> <p>Another valuable lesson was how Linux shows persistence and execution. Where Windows uses registry run keys or scheduled tasks, Linux often relies on configuration files like <code>.bashrc</code> or simple logs. Tracing package installations through <code>auth.log</code> felt very similar to reconstructing programme execution with <code>AmCache</code> and <code>ShimCache</code> in Windows. The artefacts differ but are working towards the same end goal, the same goal, to build a timeline of what was done, by who, and when.</p> <h3>Logs Tell the System's Story</h3> <p>The log files were where Linux really clicked for me. Finding out that the virtual machine once had a different hostname (tryhackme) made me realise how logs preserve the history of a system far beyond its current state. Compared to Windows event logs, Linux logs felt simpler to parse, further showing me that logs don't just capture activity, they capture identity, change, and intent.</p> <h3>What I Took Away</h3> <ul> <li><strong>Artefacts: </strong>Linux artefacts are often easier to access than Windows, but context matters more than the raw data.</li> <li><strong>Users and Groups: </strong>User and group files serve the same purpose as hives from Windows, they anchor activity to identities.</li> <li><strong>System Configuration: </strong>System configuration can be just as important as user actions when reconstructing events.</li> <li><strong>Executions: </strong>Execution evidence is everywhere if you know where to look, from package installs to shell history.</li> <li><strong>Logs: </strong>Logs preserve not just actions but the evolution of a system over time.</li> </ul> <h3>Final Thoughts</h3> <p>This room felt easier than the Windows ones, but that in itself was a lesson. Forensics isn't about how hard the artefacts are to find, it's about piecing them together into a story. Linux may present its evidence more openly than Windows, but interpretation is still the skill that matters most.</p>",
        "author": "Tom Page",
        "date_published": "27/09/2025",
        "read_time": "4 min read",
        "featured_image": "/static/images/linux-forensics.png",
        "tags": ["TryHackMe", "Linux", "Forensics", "Logs"],
        "seo_title": "TryHackMe - Linux Forensics",
        "seo_description": "Exploring the fundamentals of Linux Forensics with TryHackMe. Learning key concepts, tools, and processes to investigate security incidents effectively."
    },
    {
        "id": "windows-forensics-2",
        "title": "TryHackMe | Windows Forensics 2",
        "content": "<p><p><strong>After completing the first Windows Forensics room, I moved on to part two. This time, the focus shifted away from the registry and onto the file system. That change made it feel much more hands-on, and it pushed me to think about how evidence is actually stored, deleted, and recovered at a lower level.</strong></p> <h3>FAT vs NTFS - Different File Systems, Different Clues</h3> <p>The first part of this room revisited file systems I had only ever heard about in passing. FAT32, for example, has been around for decades and is still used in devices like SD cards and digital cameras. I knew it had limitations, but I didn't realise that those limitations (like the 4GB max file size) are exactly what make forensic analysts need to understand it. NTFS, by contrast, is far more powerful, and this room showed me how its structure (things like the Master File Table and cluster sizes) becomes essential in an investigation.</p> <h3>The Master File Table - A System's Index</h3> <p>Working with the NTFS $MFT file was eye-opening. As a developer, I've always thought of a file system as a black box that just stores things. In reality, <code>$MFT</code> is a detailed index of every file: names, sizes, timestamps, and even traces of files that have been deleted. Parsing it with forensic tools felt a lot like querying a database, and it gave me a much deeper appreciation of how operating systems keep track of everything.</p> <h3>Deleted Doesn't Mean Gone</h3> <p>One of the most striking lessons from this room was how easy it is to recover deleted files. Using Autopsy, I could not only see which files had been deleted, but also restore their contents. Seeing a supposedly deleted text file reappear with its data intact was a powerful reminder that in digital systems, deletion often just means hidden rather than erased. From a security perspective, this changes how I think about data persistence and why secure deletion methods matter.</p> <h3>Tracing Execution</h3> <p>Another big area of learning was how Windows leaves traces of programme execution. Prefetch files, timeline databases, and jump lists all record details about what was run, when, and even how long it stayed in focus. Before this, I wouldn't have guessed Windows kept that much history. As a developer, it's like discovering hidden logs of user activity that persist far longer than most people expect. For an investigator, that's invaluable. For a user, it's a bit unsettling.</p> <h3>Tools of the Trade</h3> <p>This room introduced me to more of Eric Zimmerman's tools, like MFTECmd for parsing file system metadata and PECmd for analysing Prefetch files. They felt a bit intimidating at first, running commands, parsing CSVs, and sifting through output in EZViewer, but once I got into the flow, it started to click.</p> <h3>What Stuck With Me</h3> <ul> <li><strong>File Systems: </strong>File systems hold far more information than I realised, even after deletion.</li> <li><strong>NFTS: </strong>NTFS is incredibly detailed, and forensic tools can pull out insights that would be impossible to do manually.</li> <li><strong>Windows Data Logging: </strong>Windows records a surprising amount of programme execution history, more than most users probably know.</li> <li><strong>New Tools: </strong>Learning new tools has a learning curve, but once you understand their role, they feel indispensable.</li> </ul> <h3>Final Thoughts</h3> <p>This second Windows Forensics room felt like a natural step up from the first. Instead of just reading about concepts, I was actively parsing files, recovering evidence, and piecing together activity on the system. The biggest shift for me was realising that deleted doesn't mean gone, and that the file system itself is often the strongest witness in an investigation. I'm looking forward to moving on to Linux forensics, where I expect the artefacts will be different, but the mindset of digging patiently for traces of past activity will likely stay the same.</p></p>",
        "author": "Tom Page",
        "date_published": "22/09/2025",
        "read_time": "5 min read",
        "featured_image": "/static/images/windows-forensics-2.png",
        "tags": ["TryHackMe", "Windows", "Forensics", "Autopsy", "EZTools"],
        "seo_title": "TryHackMe - Windows Forensics 2",
        "seo_description": "Exploring the fundamentals of Windows Forensics with TryHackMe. Learning key concepts, tools, and processes to investigate security incidents effectively."
    },
    {
        "id": "windows-forensics-1",
        "title": "TryHackMe | Windows Forensics 1",
        "content": "<p><strong>Continuing my journey through TryHackMe's DFIR learning path, I've just finished the first of two Windows Forensics rooms. Unlike the introductory DFIR room, this one finally put me in front of actual forensic artefacts, and I started to see how theory translates into practice. For someone from a software engineering background, this was my first real taste of digging through a system's internals.</strong></p> <h3>Windows Forensics Isn't Just Windows Knowledge</h3> <p>I already knew Windows was the most widely used desktop OS, but what surprised me was just how much of a system's behaviour is quietly stored in the background. The registry in particular was fascinating. I'd always thought of it as this scary place you don't touch unless you're following a tutorial, but in forensics, it becomes a goldmine. Everything from what software has run, to what devices were connected, to what files were recently opened, it's all in there, if you know where to look.</p> <h3>Registry Hives and Why They Matter</h3> <p>I learned that Windows stores its configuration across multiple hives, each covering different aspects of the system (accounts, security policies, installed software, etc.). Accessing these hives offline showed me just how fragile but powerful this information is. For example:</p> <ul> <li><strong>SAM Hive:</strong> Stores account details, even things like user IDs that reveal whether an account was created by the system or by a user.</li> <li><strong>AmCache & ShimCache:</strong> Provide evidence of programme execution, including hashes and full paths, which means you can trace exactly what ran and when.</li> <li><strong>NTUSER.DAT:</strong> Contains user-specific activity, such as recently accessed files and applications.</li></ul><br><p>What struck me most is that as a developer, I often focus on logs for debugging. However, registry artefacts are like a deeper log of the operating system itself, often storing details the user never realises are there.</p> <h3>Evidence of User Behaviour</h3> <p>One of my favourite parts of this room was learning how to spot traces of what users had done on the machine. For example, you can find out when a file was last accessed, what programmes were launched (and how many times), or even the password hint set for an account. It felt like piecing together what someone did step by step, rebuilding their session.</p><h3>External Devices Leave Their Own Fingerprints</h3> <p>I also hadn't appreciated how much information Windows stores about external devices like USBs. Not only can you identify the exact make and model of a device, but you can also find out the last time it was connected. This was eye-opening because in a real incident, knowing whether an attacker used removable media could completely change the response strategy.</p> <h3>Tools and the Learning Curve</h3> <p>I used Registry Explorer in this room, and honestly, the hardest part for me wasn't the analysis but just figuring out how to load the data properly. Once I got past that, I started to see why different organisations use different tools, sometimes, the challenge is just knowing how to navigate the interface. It reminded me of my first time using a complex IDE. It was overwhelming at first, but once you understand the layout, it becomes an invaluable asset.</p> <h3>What I Took Away</h3> <ul> <li>Windows systems leave far more forensic breadcrumbs than I realised.</li> <li>Forensics isn't just about finding what happened but piecing together the when and how.</li> <li>The registry, once just a scary place to avoid, is now something I see as a structured source of truth.</li> <li>Tools like Registry Explorer have a learning curve, but the payoff is being able to reconstruct user and system activity with surprising detail.</li> </ul> <h3>Final Thoughts</h3> <p>Compared to the introductory DFIR room, this one felt much more practical. It gave me the sense that forensics is less about theory and more about patient, methodical investigation. My biggest takeaway was that every action on a system leaves a trace somewhere, and the role of a forensic analyst is to know where to look and how to interpret it. I can already see how this mindset could apply back to my software work, systems don't just fail silently, they usually tell a story. You just have to be willing to dig.</p>",
        "author": "Tom Page",
        "date_published": "17/09/2025",
        "read_time": "5 min read",
        "featured_image": "/static/images/windows-forensics.png",
        "tags": ["TryHackMe", "DFIR", "Windows", "Registry Explorer", "EZTools"],
        "seo_title": "TryHackMe - Windows Forensics 1",
        "seo_description": "Exploring the fundamentals of Windows Forensics with TryHackMe. Learning key concepts, tools, and processes to investigate security incidents effectively."
    },
    {
        "id": "dfir-introduction",
        "title": "TryHackMe | DFIR: An Introduction",
        "content": "<p><strong>To begin my journey through TryHackMe's Digital Forensics and Incident Response (DFIR) module, I just completed the introductory room. Coming from a software engineering background, I'm used to thinking about how systems are built and maintained, but this was my first proper look at what happens after things go wrong.</strong></p><h3>What DFIR Actually Is</h3><p>DFIR stands for Digital Forensics and Incident Response. Before this, I vaguely knew it had something to do with investigating hacks, but now I understand it's a structured field that blends two areas:</p><ul><li><strong>Digital Forensics:</strong> Collecting and analysing artefacts (like logs, memory dumps, registry keys, etc.) that tell the story of what happened.</li><li><strong>Incident Response:</strong> Using that evidence to detect, contain, and recover from attacks.</li></ul><br><p>As a software engineer, I often think about preventing bugs. DFIR taught me that in security, you have to assume failure will happen, and be ready to handle it.</p><h3>Core Concepts That Stood Out</h3><p>Some key principles really made me rethink how fragile digital evidence can be:</p><ul><li><strong>Artefacts:</strong> Evidence left behind by attackers, such as a suspicious process or a modified registry key.</li><li><strong>Order of Volatility:</strong> Some data disappears faster than others (e.g., RAM is lost on reboot, hard drive data lasts longer).</li><li><strong>Evidence Preservation:</strong> Always work on protected copies of evidence to avoid contamination.</li><li><strong>Chain of Custody:</strong> Track who handles evidence and when to ensure findings are trusted.</li></ul><br><p>These ideas reminded me of version control in coding, both aim to keep history reliable.</p><h3>The Toolbox</h3><p>I also got a first look at some tools used in DFIR and the basic purpose of each. These where:</p><ul><li><strong>Autopsy:</strong> Open-source forensic analysis tool.</li><li><strong>Volatility:</strong> For analysing memory dumps from Windows and Linux systems.</li><li><strong>Redline & Velociraptor:</strong> Endpoint monitoring and incident response tools.</li><li><strong>KAPE:</strong> Automates collecting and parsing forensic artefacts.</li></ul><br><p>It's exciting to see parallels with development tools, like how KAPE automates repetitive tasks similar to CI/CD pipelines.</p><h3>The Incident Response Lifecycle</h3><p>This room introduced the PICERL process (Preparation, Identification, Containment, Eradication, Recovery, Lessons Learned). DFIR isn't just technical, it's also procedural and collaborative. You have to not only find what went wrong but also make sure the organisation learns from it.</p><h3>Final Thoughts</h3><p>As a first step into DFIR, this room was light on hands-on challenges but introduced me to a lot of new tools and ideas. For me, my biggest takeaway was that security work doesn't end when prevention fails, but that's when it begins.</p><p>I'm looking forward to exploring the next rooms, diving deeper into Windows and Linux forensics. It's a completely different way of thinking compared to my software engineering classes, and I can already see how useful it will be for understanding how systems behave under attack.</p>",
        "author": "Tom Page",
        "date_published": "10/09/2025",
        "read_time": "4 min read",
        "featured_image": "/static/images/dfir-intro.png",
        "tags": ["TryHackMe", "DFIR", "Autopsy", "Volatility", "Redline", "Velociraptor", "KAPE"],
        "seo_title": "TryHackMe - DFIR: An Introduction",
        "seo_description": "Exploring the fundamentals of Digital Forensics and Incident Response (DFIR) with TryHackMe. Learning key concepts, tools, and processes to investigate security incidents effectively."
    }
]
